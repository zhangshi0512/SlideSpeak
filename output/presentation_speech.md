Hello everyone. Today, I will be presenting about On Device AI. We'll start by introducing what On-Device AI is and its basics. Then we’ll explore the advantages it offers and some of the challenges involved. After that, we'll delve into different techniques used for implementing On-Device AI. Finally, I’ll share examples of current applications where On-Device AI is being used. [PAUSE=1]

Let's discuss introduction to On-Device AI. On-device AI is all about processing machine learning models directly on devices like smartphones or IoT sensors. This not only gives us faster response times and increased privacy, but also localized intelligence that can provide more personalized experiences without constantly relying solely on cloud servers. It significantly improves our user experience by reducing latency and better utilizing resources, making things run smoother and quicker. Let's pause here for a moment. [PAUSE=1] Moving on to our next topic: Advantages of On-Device AI. [SLIDE CHANGE]

Let's discuss Advantages of On-Device AI. Reduced latency is one big advantage, eliminating the need for data transfer to the cloud which speeds up responses significantly. For instance, it makes real-time interactions like voice commands and augmented reality feel much more instant. Additionally, processing data locally keeps sensitive information private as it doesn't leave the device. This reduces privacy risks by keeping personal details confidential and only analyzing them where they belong—on your own device. Finally, on-device AI also enhances battery life because local tasks are less energy-intensive compared to remote computing processes. This means that devices don’t have to work as hard, leading to longer operational hours without needing a recharge so frequently. Let's pause here for a moment. [PAUSE=1] Moving on to our next topic: Challenges of On-Device AI. [SLIDE CHANGE]

Let's discuss the challenges of on-device AI. Power constraints are a major hurdle; limited computing power can significantly affect model performance. Running complex machine learning models requires more energy, and in low-power environments, this is not always available. This leads to slower response times for users. Resource management is also critical here — efficiently managing things like memory and processing cores is essential. For instance, memory fragmentation can cause the model to run slower or crash altogether. Overloading a single processing core with multiple tasks can quickly deplete system resources. On top of that, ensuring data security in local storage and transmission is another big challenge we face. Local storage can be a target for attackers who might exploit vulnerabilities to extract or manipulate data. Transmission of data over local networks must be encrypted to prevent interception by third parties. [PAUSE=1] Moving on to our next topic: Techniques for On-Device AI. [SLIDE CHANGE]

Let's discuss Techniques for On-Device AI. Model compression is key, where we reduce the size of models to fit available device hardware constraints. This can be achieved by pruning weights, merging layers, and simplifying architectures. We also use techniques like Knowledge Distillation to further compress these models. Quantization comes next, which involves lowering the precision of numbers used by neural networks to reduce computational load. To make it even more efficient, we use schemes like QAT (Quantized Asymmetric Training) and QNN (Quantized Neural Networks), considering their impact on model accuracy for specific tasks. Finally, Federated Learning allows us to combine training data from various devices while maintaining user privacy by training models locally with mini-batches of data using secure aggregation methods. Let's pause here for a moment. [PAUSE=1] Moving on to our next topic: Current Applications. [SLIDE CHANGE]

Let's discuss Current Applications. Smart Home Automation is really interesting where devices can learn your routines without needing to connect to the cloud. For example, smart lights adjust brightness based on ambient light, and thermostats optimize heating or cooling when you're home. In healthcare, we have localized monitoring that allows for diagnoses and treatment recommendations right from wearable devices. Health apps also track health metrics locally and analyze data to spot early warning signs without needing to connect to a cloud server. [PAUSE=1]

Thank you for your attention. [PAUSE=1] The presentation covered the introduction to On-Device AI, its advantages, challenges, techniques, and current applications. Remembering these points can help in understanding how devices are becoming smarter without relying solely on cloud services. If you have any questions, I'd be happy to address them now. [PAUSE=2]